# Alignment Faking Detection Research

Three months of experiments detecting alignment faking (AF) in LLM chain-of-thought reasoning using interpretability techniques.


## Citation

```bibtex
@misc{bigsnarfdude2026afdetection,
  title={Alignment Faking Detection: A Two-Month Research Journey},
  author={bigsnarfdude},
  year={2026},
  url={https://github.com/bigsnarfdude/af-research-writeup}
}
```

## License

MIT
